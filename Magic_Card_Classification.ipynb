{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Magic Cards by Role Performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "My goal is to classify Magic: the Gathering cards by the role they play in their respective decks. <br>\n",
    "<br>\n",
    "Magic: the Gathering is a competitive card game. One of the major ways that Magic is played is a format called draft. In drafts 8 players will sit down at a table with three sealed packs of 15 cards each. Players will open the first pack and select one card from it for their deck. They will then pass the remaining 14 cards to the player on their left. When they recieve 14 cards from the player on their right, they will pick one card and pass the remaining 13 cards along. As each pack is passed around the table each player selects one card and passes the rest along until all the cards are gone. Then each player opens the second pack and the process is repeated until all the cards are gone. Once the third pack is drafted, each player should have selected 45 cards for their deck. They will then choose the best 22-24 of those cards to comprise their deck.<br>\n",
    "<br>\n",
    "All of the different cards fill different roles in a deck. Some cards are creatures that can attack the opponent to win the game. Some cards destroy opponents creatures. Some cards allow you to draw more cards, others force your opponent to discard cards. Some prevent the opponent from playing their cards, some negate the effects of the opponents cards after they've been played. In order to build the best deck, you need to identify the role that all of your cards will play. For example if all of your cards make the creatures you play better, but your deck contains no creatures for those cards to help, you are unlikely to win. <br>\n",
    "<br>\n",
    "My goal for this project is to build a classifier that will read the text on Magic cards and classify them by role. This is a necessary step for training a learner to build synergistic draft decks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "For data, I am using a dataset generated through the mtgsdk library. The library allows me to create Card objects for every Magic card in print. For each of those Card objects I can access the text printed on the card as well as other metadata.<br>\n",
    "<br>\n",
    "Unfortunately the role of each card in a deck is not a part of the metadata provided. I need to generate those labels by hand. Because there are approximately 20,000 Magic cards in print I have chosen a subset to work with. I have chosen to include cards that are legal in the Pioneer format, which includes cards printed since October 2012. From those Pioneer legal cards I have selected all cards that have the type Instant or the type Sorcery. I chose to use instants and sorceries because they have a one time effect on the game. They do whatever the text of the card says and then are discarded from play. <br>\n",
    "<br>\n",
    "All told, there were 1686 instants and sorceries printed since Oct 2012. I wrote a script to label them 100 at a time and then save the labels in .txt files. I wound up dropping one row in which I mislabeled a card, bringing the total to 1685 cards. For each card I have the label, the text on the card, and the type of the card (instant vs sorcery).<br>\n",
    "<br>\n",
    "I have not included the actual dataset generation and labeling in this file. Once the dataset was generated, the labels were pickled and saved to a file named 'y.data' while the card objects were pickled and saved to 'IS.data'. In this file I simply load the pickled data I previously generated.<br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of Metadata\n",
    "The primary data I will be working with is the card text. It is the text that describes what the card does when played. I will also be looking at the card type. For this dataset it will be restricted to 'Instant' or 'Sorcery'. Instants are cards that can be played at any time during the game, while Sorceries are cards that can be played only at specific moments during your turn. The last category is the Converted Mana Cost (cmc) of each card. It is the total amount of resources that need to be spent to play the card. <br>\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing useful libraries\n",
    "import mtgsdk\n",
    "import pickle\n",
    "from mtgsdk import Set\n",
    "from mtgsdk import Card\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting by loading the complete list of labels\n",
    "with open('y.data', 'rb') as filehandle:\n",
    "     y = pickle.load(filehandle)\n",
    "#loading the complete list of instants and sorceries\n",
    "with open('IS.data', 'rb') as filehandle:\n",
    "    IS = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling out card text and card type\n",
    "X_text=[]\n",
    "X_type=[]\n",
    "X_cmc=[]\n",
    "for thing in IS:\n",
    "    X_text.append(thing.text)\n",
    "    X_type.append(thing.type)\n",
    "    X_cmc.append(thing.cmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making them into pandas series\n",
    "Type=pd.Series(X_type)\n",
    "Y=pd.Series(y)\n",
    "Text=pd.Series(X_text)\n",
    "CMC=pd.Series(X_cmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['draw', 'cond', 'token', 'trick', 'misc', 'tempo', 'threaten',\n",
       "       'rdead', 'removal', 'burn', 'pump', 'counter', 'discard', 'aerem',\n",
       "       'tutor', 'sweeper', 'ramp', 'mill', ''], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking labels since I hand labeled them\n",
    "Y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cont.\n",
    "\n",
    "When I labeled the target I chose 18 different categories for the cards. One card was mislabeled as ' ', this will be deleted in the following cells. The dataset isn't balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trick       262\n",
       "cond        226\n",
       "draw        186\n",
       "removal     127\n",
       "tempo       113\n",
       "token       104\n",
       "misc         99\n",
       "counter      98\n",
       "burn         91\n",
       "sweeper      73\n",
       "aerem        73\n",
       "discard      54\n",
       "tutor        50\n",
       "pump         40\n",
       "threaten     32\n",
       "rdead        28\n",
       "ramp         18\n",
       "mill         11\n",
       "              1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at counts will probably use this to trim the dataset\n",
    "Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe\n",
    "frame={'type':Type,'text':Text,'cmc':CMC,'y':y}\n",
    "df=pd.DataFrame(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the row with a missing value\n",
    "df=df[df.y!='']\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cont.\n",
    "The first ten entries in the dataframe are displayed below. The dataframe contains the text of the card, whether it is an instant or a sorcery, and the converted mana cost (cmc) of the card. The y label is also included in the dataframe. Since the text of the card is truncated when looking at the full dataframe, I have also printed the full text of the first 10 cards in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "      <th>cmc</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Choose one or both —\\n• Return target creature...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>draw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Choose one —\\n• Target player sacrifices an ar...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>cond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Instant</td>\n",
       "      <td>Put nine +1/+1 counters on target land you con...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>token</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Instant</td>\n",
       "      <td>Up to two target creatures you control each de...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>cond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Instant</td>\n",
       "      <td>Put a +1/+1 counter on target creature. That c...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>trick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Up to one target creature gets -2/-2 until end...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>cond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Instant</td>\n",
       "      <td>Blindblast deals 1 damage to target creature. ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>cond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Instant</td>\n",
       "      <td>This spell costs {3} less to cast if you contr...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Tap all creatures your opponents control. Crea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>tempo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sorcery</td>\n",
       "      <td>Look at the top three cards of your library. Y...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>draw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                               text  cmc      y\n",
       "0  Sorcery  Choose one or both —\\n• Return target creature...  2.0   draw\n",
       "1  Sorcery  Choose one —\\n• Target player sacrifices an ar...  2.0   cond\n",
       "2  Instant  Put nine +1/+1 counters on target land you con...  5.0  token\n",
       "3  Instant  Up to two target creatures you control each de...  3.0   cond\n",
       "4  Instant  Put a +1/+1 counter on target creature. That c...  2.0  trick\n",
       "5  Sorcery  Up to one target creature gets -2/-2 until end...  3.0   cond\n",
       "6  Instant  Blindblast deals 1 damage to target creature. ...  3.0   cond\n",
       "7  Instant  This spell costs {3} less to cast if you contr...  4.0   misc\n",
       "8  Sorcery  Tap all creatures your opponents control. Crea...  5.0  tempo\n",
       "9  Sorcery  Look at the top three cards of your library. Y...  2.0   draw"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose one or both —\n",
      "• Return target creature card from your graveyard to your hand.\n",
      "• Return target planeswalker card from your graveyard to your hand.\n",
      "\n",
      "Choose one —\n",
      "• Target player sacrifices an artifact.\n",
      "• Target player sacrifices a creature.\n",
      "• Target player sacrifices a planeswalker.\n",
      "\n",
      "Put nine +1/+1 counters on target land you control. It becomes a legendary 0/0 Elemental creature with haste named Vitu-Ghazi. It's still a land.\n",
      "\n",
      "Up to two target creatures you control each deal damage equal to their power to another target creature.\n",
      "\n",
      "Put a +1/+1 counter on target creature. That creature gains first strike until end of turn. You gain 2 life.\n",
      "\n",
      "Up to one target creature gets -2/-2 until end of turn. Amass 2. (Put two +1/+1 counters on an Army you control. If you don't control one, create a 0/0 black Zombie Army creature token first.)\n",
      "\n",
      "Blindblast deals 1 damage to target creature. That creature can't block this turn.\n",
      "Draw a card.\n",
      "\n",
      "This spell costs {3} less to cast if you control a creature with power 4 or greater.\n",
      "Change the target of target spell or ability with a single target.\n",
      "\n",
      "Tap all creatures your opponents control. Creatures you control gain lifelink until end of turn.\n",
      "\n",
      "Look at the top three cards of your library. You may reveal a permanent card from among them and put it into your hand. Put the rest on the bottom of your library in any order. You gain 3 life.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for thing in df.text.head(10):\n",
    "    print(thing+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Development\n",
    "\n",
    "I built my first model using just the text data from each card. I built a pipeline that used a CountVectorizer with nltk's default tokenization. I then fed that into a TfidfTransformer to generated tf-idf scores for all of the words used. Ultimately I used a LinearSVC as a classifier. I chose to use a LinearSVC because it tends to work quickly and effectively with datasets that contain many sparse features. I chose not to remove stopwords, or symbols in the preprocessing stage, as they often contain important contextual information.<br>\n",
    "<br>\n",
    "The initial model achieved .731 +/- 0.058 accuracy on 10-fold cross validation. This is an unbalanced 18 class problem, so I'm pleased with that initial accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prob redundant but just setting up my X and Ys\n",
    "X=df.text\n",
    "Y=df.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.71186441 0.78285714 0.80346821 0.68235294 0.71428571 0.67857143\n",
      " 0.72289157 0.69090909 0.67283951 0.85093168]\n",
      "CV accuracy: 0.731 +/- 0.058\n"
     ]
    }
   ],
   "source": [
    "#running and scoring a pipeline on just card text\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_lin = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', LinearSVC(class_weight='balanced'))\n",
    "                   ])\n",
    "scores = cross_val_score(estimator=svm_lin,\n",
    "                         X=X,\n",
    "                         y=Y,\n",
    "                         cv=10,\n",
    "                         n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development Cont.\n",
    "My next step was to look at n-grams. The categories the cards fall into are fairly nuanced. For example, 'destroy target creature' falls into the 'removal' category, 'destroy all creatures' falls into the 'sweeper' category, and 'destroy target creature with power 2 or less' falls into the 'conditional removal' category. By looking at n-grams I hope to capture more of that nuance and improve predictive accuracy.<br>\n",
    "<br>\n",
    "To incorporate n-grams, I used a TfidfVectorizer with ngram_range of (1,3). I tried several different ranges of ngram_range  with 10-fold cross validation and found (1,3) to be the best fit.<br>\n",
    "<br>\n",
    "I made a new dataframe (X2) that contained the feature names and tf-idf scores for the n-grams. I also included the cmc (converted mana cost) of the card and a binary feature instant_or_sorcery that differentiated instants and sorceries. The dataframe X2 is shown below.<br>\n",
    "<br>\n",
    "Again i used a linearSVC for classification. It achieved a 10-fold cross validation accuracy of .777 +/-0.055. This was a significant improvement from the .731 +/-0.058 from when n-grams, cmc, and instant_or_sorcery weren't considered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now looking at n-grams\n",
    "tfidfvect=TfidfVectorizer(ngram_range=(1,3))\n",
    "X2=tfidfvect.fit_transform(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a dataframe\n",
    "X2=pd.DataFrame(X2.todense(),columns=tfidfvect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding CMC to see if it helps\n",
    "df['cmc'].unique()\n",
    "X2['_cmc']=df['cmc']\n",
    "#getting an error where a single nan appears when I set X2['_cmc']=df['cmc']\n",
    "X2['_cmc'].unique()\n",
    "#imputing mean CMC for the one nan\n",
    "X2=X2.fillna(X2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding an instant_or_sorcery feature derived from type. 1 if instant 0 if sorcery\n",
    "X2['_type']=df['type']\n",
    "X2['instant_or_sorcery'] = np.where(X2['_type']=='Instant', 1, 0)\n",
    "X2.drop(['_type'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>10 damage</th>\n",
       "      <th>10 damage divided</th>\n",
       "      <th>10 life</th>\n",
       "      <th>10 life instead</th>\n",
       "      <th>10 or</th>\n",
       "      <th>10 or more</th>\n",
       "      <th>13</th>\n",
       "      <th>13 13</th>\n",
       "      <th>13 13 until</th>\n",
       "      <th>...</th>\n",
       "      <th>zombie in addition</th>\n",
       "      <th>zombie that</th>\n",
       "      <th>zombie that player</th>\n",
       "      <th>zombie this</th>\n",
       "      <th>zombie this turn</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zombies you</th>\n",
       "      <th>zombies you control</th>\n",
       "      <th>_cmc</th>\n",
       "      <th>instant_or_sorcery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1685 rows × 13058 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       10  10 damage  10 damage divided  10 life  10 life instead  10 or  \\\n",
       "0     0.0        0.0                0.0      0.0              0.0    0.0   \n",
       "1     0.0        0.0                0.0      0.0              0.0    0.0   \n",
       "2     0.0        0.0                0.0      0.0              0.0    0.0   \n",
       "3     0.0        0.0                0.0      0.0              0.0    0.0   \n",
       "4     0.0        0.0                0.0      0.0              0.0    0.0   \n",
       "...   ...        ...                ...      ...              ...    ...   \n",
       "1680  0.0        0.0                0.0      0.0              0.0    0.0   \n",
       "1681  0.0        0.0                0.0      0.0              0.0    0.0   \n",
       "1682  0.0        0.0                0.0      0.0              0.0    0.0   \n",
       "1683  0.0        0.0                0.0      0.0              0.0    0.0   \n",
       "1684  0.0        0.0                0.0      0.0              0.0    0.0   \n",
       "\n",
       "      10 or more   13  13 13  13 13 until  ...  zombie in addition  \\\n",
       "0            0.0  0.0    0.0          0.0  ...                 0.0   \n",
       "1            0.0  0.0    0.0          0.0  ...                 0.0   \n",
       "2            0.0  0.0    0.0          0.0  ...                 0.0   \n",
       "3            0.0  0.0    0.0          0.0  ...                 0.0   \n",
       "4            0.0  0.0    0.0          0.0  ...                 0.0   \n",
       "...          ...  ...    ...          ...  ...                 ...   \n",
       "1680         0.0  0.0    0.0          0.0  ...                 0.0   \n",
       "1681         0.0  0.0    0.0          0.0  ...                 0.0   \n",
       "1682         0.0  0.0    0.0          0.0  ...                 0.0   \n",
       "1683         0.0  0.0    0.0          0.0  ...                 0.0   \n",
       "1684         0.0  0.0    0.0          0.0  ...                 0.0   \n",
       "\n",
       "      zombie that  zombie that player  zombie this  zombie this turn  zombies  \\\n",
       "0             0.0                 0.0          0.0               0.0      0.0   \n",
       "1             0.0                 0.0          0.0               0.0      0.0   \n",
       "2             0.0                 0.0          0.0               0.0      0.0   \n",
       "3             0.0                 0.0          0.0               0.0      0.0   \n",
       "4             0.0                 0.0          0.0               0.0      0.0   \n",
       "...           ...                 ...          ...               ...      ...   \n",
       "1680          0.0                 0.0          0.0               0.0      0.0   \n",
       "1681          0.0                 0.0          0.0               0.0      0.0   \n",
       "1682          0.0                 0.0          0.0               0.0      0.0   \n",
       "1683          0.0                 0.0          0.0               0.0      0.0   \n",
       "1684          0.0                 0.0          0.0               0.0      0.0   \n",
       "\n",
       "      zombies you  zombies you control  _cmc  instant_or_sorcery  \n",
       "0             0.0                  0.0   2.0                   0  \n",
       "1             0.0                  0.0   2.0                   0  \n",
       "2             0.0                  0.0   5.0                   1  \n",
       "3             0.0                  0.0   3.0                   1  \n",
       "4             0.0                  0.0   2.0                   1  \n",
       "...           ...                  ...   ...                 ...  \n",
       "1680          0.0                  0.0   1.0                   1  \n",
       "1681          0.0                  0.0   2.0                   1  \n",
       "1682          0.0                  0.0   2.0                   0  \n",
       "1683          0.0                  0.0   4.0                   1  \n",
       "1684          0.0                  0.0   1.0                   1  \n",
       "\n",
       "[1685 rows x 13058 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [0.76836158 0.82857143 0.80924855 0.75882353 0.83333333 0.71428571\n",
      " 0.72891566 0.72727273 0.72222222 0.88198758]\n",
      "CV accuracy: 0.777 +/- 0.055\n"
     ]
    }
   ],
   "source": [
    "#trying a linearSVC with ngram_range=(1,3) and CMC and instant_or_sorcery added\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    scores = cross_val_score(estimator=LinearSVC(class_weight='balanced'),\n",
    "                             X=X2,\n",
    "                             y=Y,\n",
    "                             cv=10,\n",
    "                             n_jobs=1)\n",
    "    print('CV accuracy scores: %s' % scores)\n",
    "    print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Development Cont.\n",
    "Next I tried using word embeddings rather than tf-idf scores. I used gensim word2vec to generate a Continuous Bag of Words (CBOW) model and a Skip-Gram model. For each model I used hiden layer size 200, window size of 5, min count of 1, and 20 iterations. I generated an X-matrix for each using the mean of the word vectors.<br>\n",
    "<br>\n",
    "By using word embeddings, I was able to reduce the number of features down to 200. This meant I was no longer limited to LinearSVC for speed reasons. I set up a list of 5 classifiers that included a LinearSVC, RandomForest, GaussianNB (Naive-Bayes), rbf kernel SVC, and Logistic Regression. I then iterated through that list and tried 10-fold cross validation for each using the cbow model and the skip-gram model.<br>\n",
    "<br>\n",
    "Unfortunately the highest accuracy was the skip-gram using LinearSVC with .656 +/- 0.058 accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying gensim word2vec\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word tokenizing the documents\n",
    "w2vText = [word_tokenize(doc) for doc in df['text']]\n",
    "#encoding y\n",
    "ydocs = np.array([list(Y.unique()).index(_) for _ in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating a cbow model\n",
    "cbowmodel = Word2Vec(w2vText, size=200, sg=0, window=5, min_count=1, iter=20, workers=4)\n",
    "Xdocs_cbow = np.array([np.mean([cbowmodel.wv[word] for word in doc], axis=0) for doc in w2vText])\n",
    "#generating a skip-gram model\n",
    "sgmodel = Word2Vec(w2vText, size=200, sg=1, window=5, min_count=1, iter=20, workers=4)\n",
    "Xdocs_sg = np.array([np.mean([sgmodel.wv[word] for word in doc], axis=0) for doc in w2vText])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing classifiers to try\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making some lists to iterate through for model evaluation\n",
    "clfs=[LinearSVC(class_weight='balanced'),GaussianNB(),RandomForestClassifier(n_jobs=4, n_estimators=300, max_depth=10, random_state=None, class_weight='balanced'),SVC(kernel='rbf', gamma='scale', class_weight='balanced'),LogisticRegression(solver='lbfgs', multi_class='auto', max_iter =300, class_weight='balanced')]\n",
    "Xes=[Xdocs_cbow,Xdocs_sg]\n",
    "X_labels=['CBOW','Skip-Gram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBOW\n",
      "LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n",
      "CV accuracy: 0.614 +/- 0.071 \n",
      "\n",
      "CBOW\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "CV accuracy: 0.426 +/- 0.053 \n",
      "\n",
      "CBOW\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=10, max_features='auto',\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=300, n_jobs=4, oob_score=False,\n",
      "                       random_state=None, verbose=0, warm_start=False)\n",
      "CV accuracy: 0.581 +/- 0.060 \n",
      "\n",
      "CBOW\n",
      "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "CV accuracy: 0.512 +/- 0.073 \n",
      "\n",
      "CBOW\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=300, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "CV accuracy: 0.514 +/- 0.063 \n",
      "\n",
      "Skip-Gram\n",
      "LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0)\n",
      "CV accuracy: 0.661 +/- 0.060 \n",
      "\n",
      "Skip-Gram\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "CV accuracy: 0.504 +/- 0.060 \n",
      "\n",
      "Skip-Gram\n",
      "RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
      "                       criterion='gini', max_depth=10, max_features='auto',\n",
      "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=300, n_jobs=4, oob_score=False,\n",
      "                       random_state=None, verbose=0, warm_start=False)\n",
      "CV accuracy: 0.631 +/- 0.051 \n",
      "\n",
      "Skip-Gram\n",
      "SVC(C=1.0, cache_size=200, class_weight='balanced', coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "CV accuracy: 0.578 +/- 0.066 \n",
      "\n",
      "Skip-Gram\n",
      "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=300, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "CV accuracy: 0.564 +/- 0.056 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#catching convergence errors\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    #doing cbow first then skip-gram\n",
    "    for Xdocs,xlab in zip(Xes,X_labels):\n",
    "        #trying each classifier\n",
    "        for clf in clfs:\n",
    "            scores = cross_val_score(estimator=clf,\n",
    "                             X=Xdocs,\n",
    "                             y=ydocs,\n",
    "                             cv=10,\n",
    "                             n_jobs=1)\n",
    "            #print('\\n')\n",
    "            print(xlab)\n",
    "            print(clf)\n",
    "            #print('CV accuracy scores: %s' % scores)\n",
    "            print('CV accuracy: %.3f +/- %.3f \\n' % (np.mean(scores), np.std(scores)))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "I found tf-idf to work much better with the dataset than word embedding did. The two models that used tf-idf both exceeded the best word embedding model on 10-fold cross validation. Ultimately the the model that performed best was the tf-idf model that used n-grams and included cmc and instant_or_sorcery. That model achieved 10-fold cross validation accuracy of 0.777 +/- 0.055. Considering this is an unbalanced 18-class problem, I am very pleased with that perfomance. Especially considering how much overlap and nuance exists between the classes.<br>\n",
    "<br>\n",
    "I think further impovements would come from labeling the data differently. I think the model would achieve higher accuracy if I reduced the number of levels in the target variable from 18 down to around 10. I could do this by combining similar categories like 'conditional removal' and 'removal' or 'pump' spells and 'combat tricks'. I could also create a 'multiple' category that included spells that combine two categories. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
